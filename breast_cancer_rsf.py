# -*- coding: utf-8 -*-
"""Breast_cancer_RSF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gcxfxlh_g0zSISNltYCzY6pWQf0vhNU4
"""

# Importing required Libraries


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from scipy.stats import stats
import statistics as st

from sklearn.preprocessing import LabelEncoder



### Classifiers and Predictions
from sklearn.impute import KNNImputer
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_validate

from sklearn.neighbors import KNeighborsClassifier

df = pd.read_csv("/content/sample_data/Breast Cancer METABRIC.csv")
df.head()

df.shape

"""#**DATA CLEANING**

"""

df.isnull().sum()

"""**Above figures in each column names are the amount of missing values in the dataset per each column**

#**Filling the missing values with "forward-filling method" for all X-features**
"""

for col in df.columns:
    df[col] = df[col].fillna(method='ffill')
    df[col] = df[col].fillna(method='bfill')

"""**We need to drop the "Patient's Vital Status" column since its the same as "Overall Survival Status" column**"""

# Assuming your DataFrame is named df
columns_to_drop = ["Patient's Vital Status", "Patient ID"]

# Drop the specified columns
df.drop(columns=columns_to_drop, inplace=True)

df.isnull().sum()

"""**Now all missing values have been filled, except for only Overall Survival status which is our target vaiable to predict and estimate the survival analysis on**

#**Exploratory Data Analysis**
"""

df.describe()#.to_csv("summary.csv")

"""**Summary grouped by Over all survial status**"""

df.groupby("Overall Survival Status").mean()#.to_csv("Grouped by mean summary.csv")

"""**Summary of categorical variables**"""

df.describe(include='object')

"""#**Univariate Visualizations**

**Histogram for Age**
"""

ps = df["Age at Diagnosis"].hist()
ps.set_xlabel('Age')
ps.set_ylabel('Frequency')
ps.set_title('Distribution of Age')

"""**Distribution of Gender**"""

sns.countplot(x='Sex', data = df)

sns.countplot( x = "Overall Survival Status", data=df)
plt.xlabel("Patient's vital Status")
plt.ylabel("Frequency")
plt.title("Distribution of Patients Vital Status")
plt.show()

sns.countplot( x = "Overall Survival Status", data=df)
plt.xlabel("Patient's vital Status")
plt.ylabel("Frequency")
plt.title("Distribution of Patients Vital Status")
plt.show()

"""#**Distribution of Cancer Type**"""

plt.pie(df['Cancer Type'].value_counts(), labels = ["Breast Cancer", "Breast Sarcoma"], colors = sns.color_palette("YlOrBr"), autopct = '%1.1f%%')
plt.title("Pie chart for cancer Type")
plt.show()
pass

"""#**Bi/Multi- Variate Visualizations**

**Patient Vital Status with respect to HER2 status**
"""

sns.set_palette("bright")

with sns.axes_style(style='whitegrid'):
    g = sns.catplot(x="Overall Survival Status", col="HER2 Status", col_wrap=3, data=df, kind="count", height=5.0, aspect=0.80, palette=['Red', 'Blue'])

"""**From the above chart, alot of negative HER2 status are living where lot of them also dies of the diseases and other diseases as well, compare to the positive HER2 status patients, with most of them dying of the diseases than those living, where little of them died of other causes**

#**Relationships of the variables**
"""

corr_mat = df.corr()
corr_mat.to_csv("correlation.csv")

sns.heatmap(corr_mat, square = True, cmap = 'Blues')
pass

"""#**Part 2**
#**Structuring the data to train and test Predictive Model**

**Filtering Testing and training dataset from the dataset (all target mising rows)**

**Note:**
The train data will be all the rows with non-empty values of our target variable, that is, since overall Survival Status is our target variable with 528 rows of missing values, the train data will then be all the rows where Survival status is not empty, while the test data will thn be all the rows where survival status is empty so we can train the training data and use it t predict the test data where the target values are missing.
"""

df.head()
print(df.shape)

df["Overall Survival Status"].unique()

df

from sklearn.preprocessing import LabelEncoder

# Identify categorical columns
cat_columns = df.select_dtypes(include=['object']).columns

# Create a LabelEncoder instance
label_encoder = LabelEncoder()

# Apply label encoding to all categorical columns
df[cat_columns] = df[cat_columns].apply(lambda x: label_encoder.fit_transform(x.astype(str)))

# Display the updated DataFrame
df

df.info()

"""#**Fitting Model**

#**Random Survival Forest**
"""

!pip show scikit-learn
!pip install scikit-survival

# import pandas as pd
# import numpy as np
# from sklearn.model_selection import train_test_split
# from sksurv.ensemble import RandomSurvivalForest
# from sksurv.metrics import concordance_index_censored

# # Assuming your data is stored in a DataFrame called 'df'
# # You may need to adapt the column names based on your actual DataFrame

# # Features (X) and target variable (y) for survival analysis
# X = df.drop(['Overall Survival Status'], axis=1)  # Exclude the target variable
# y = df[['Overall Survival Status', 'Overall Survival (Months)']]

# # Split the data into training and testing sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Example data preprocessing (you may need to adjust based on your dataset)
# # Handle missing values only for numeric columns
# numeric_cols = X_train.select_dtypes(include=[np.number]).columns
# X_train[numeric_cols] = X_train[numeric_cols].fillna(X_train[numeric_cols].mean())
# X_test[numeric_cols] = X_test[numeric_cols].fillna(X_test[numeric_cols].mean())

# # Encode categorical variables (if needed)
# X_train_encoded = pd.get_dummies(X_train)
# X_test_encoded = pd.get_dummies(X_test)

# # Ensure consistent features in training and test sets
# common_columns = list(set(X_train_encoded.columns) & set(X_test_encoded.columns))
# X_train_encoded = X_train_encoded[common_columns]
# X_test_encoded = X_test_encoded[common_columns]

# # Ensure the target variable is structured correctly for survival analysis
# y_train_structured = np.array(list(zip(y_train['Overall Survival Status'], y_train['Overall Survival (Months)'])),
#                                dtype=[('status', '?'), ('time', '<f8')])

# # Create a Random Survival Forest model
# rsf = RandomSurvivalForest(n_estimators=100, random_state=42)

# # Train the model
# rsf.fit(X_train_encoded, y_train_structured)

# # Predict the survival probabilities for the test set
# survival_probs = rsf.predict_survival_function(X_test_encoded)

# # Convert "Overall Survival Status" to boolean array
# y_test["Overall Survival Status"] = y_test["Overall Survival Status"].astype(bool)

# # Evaluate the model using the concordance index
# concordance_index = concordance_index_censored(y_test["Overall Survival Status"], y_test["Overall Survival (Months)"], rsf.predict(X_test_encoded))
# print(f"Concordance Index: {concordance_index}")

# !pip install lifelines

# !pip install shap lime

# import shap
# from sksurv.ensemble import RandomSurvivalForest

# # Train the Random Survival Forest model
# rsf = RandomSurvivalForest(n_estimators=100, random_state=42)
# rsf.fit(X_train_encoded, y_train_structured)

# # # Create a callable function for the model
# predict_function = lambda x: rsf.predict(x)

# # # Choose a random subset of instances for explanation
# subset_indices = np.random.choice(len(X_test_encoded), size=100, replace=False)
# X_subset = X_test_encoded.iloc[subset_indices]

# # # SHAP
# explainer = shap.Explainer(predict_function, X_train_encoded)
# shap_values_subset = explainer.shap_values(X_subset)

# # # Display SHAP summary plot
# shap.summary_plot(shap_values_subset, X_subset, feature_names=X_test_encoded.columns)

# import lime
# import lime.lime_tabular
# from sksurv.ensemble import RandomSurvivalForest

# # Create a Random Survival Forest model
# rsf = RandomSurvivalForest(n_estimators=100, random_state=42)

# # Train the model
# rsf.fit(X_train_encoded, y_train_structured)

# # Create a LIME explainer
# lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train_encoded.values, mode="regression", feature_names=X_train_encoded.columns)

# # Explain the prediction for the first instance in the test set
# lime_explanation = lime_explainer.explain_instance(X_test_encoded.iloc[0], rsf.predict, num_features=len(X_test_encoded.columns))

# # Display the explanation
# lime_explanation.show_in_notebook()

"""#**Column remove and fit the model again**"""

df

df.isnull().sum()

columns = ['Sex', 'Tumor Other Histologic Subtype', 'Neoplasm Histologic Grade', 'Cellularity', 'Lymph nodes examined positive', 'HER2 Status', 'Cohort', 'Radio Therapy', 'Inferred Menopausal State',
'PR Status']
for col in columns:
    df = df.drop(col, axis=1)
df

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sksurv.ensemble import RandomSurvivalForest
from sksurv.metrics import concordance_index_censored

# Assuming your data is stored in a DataFrame called 'df'
# You may need to adapt the column names based on your actual DataFrame

# Features (X) and target variable (y) for survival analysis
X = df.drop(['Overall Survival Status'], axis=1)  # Exclude the target variable
y = df[['Overall Survival Status', 'Overall Survival (Months)']]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Example data preprocessing (you may need to adjust based on your dataset)
# Handle missing values only for numeric columns
numeric_cols = X_train.select_dtypes(include=[np.number]).columns
X_train[numeric_cols] = X_train[numeric_cols].fillna(X_train[numeric_cols].mean())
X_test[numeric_cols] = X_test[numeric_cols].fillna(X_test[numeric_cols].mean())

# Encode categorical variables (if needed)
X_train_encoded = pd.get_dummies(X_train)
X_test_encoded = pd.get_dummies(X_test)

# Ensure consistent features in training and test sets
common_columns = list(set(X_train_encoded.columns) & set(X_test_encoded.columns))
X_train_encoded = X_train_encoded[common_columns]
X_test_encoded = X_test_encoded[common_columns]

# Ensure the target variable is structured correctly for survival analysis
y_train_structured = np.array(list(zip(y_train['Overall Survival Status'], y_train['Overall Survival (Months)'])),
                               dtype=[('status', '?'), ('time', '<f8')])

# Create a Random Survival Forest model
rsf = RandomSurvivalForest(n_estimators=100, random_state=42)

# Train the model
rsf.fit(X_train_encoded, y_train_structured)

# Predict the survival probabilities for the test set
survival_probs = rsf.predict_survival_function(X_test_encoded)

# Convert "Overall Survival Status" to boolean array
y_test["Overall Survival Status"] = y_test["Overall Survival Status"].astype(bool)

# Evaluate the model using the concordance index
concordance_index = concordance_index_censored(y_test["Overall Survival Status"], y_test["Overall Survival (Months)"], rsf.predict(X_test_encoded))
print(f"Concordance Index: {concordance_index}")

# Function to plot survival curves
def plot_survival_curves(survival_probs, title="Survival Curves"):
    plt.figure(figsize=(10, 6))

    for i, s in enumerate(survival_probs):
        plt.step(s.x, s.y, where="post", label=f"Curve {i + 1}")

    plt.title(title)
    plt.xlabel("Time (Months)")
    plt.ylabel("Survival Probability")
    plt.legend()
    plt.show()

# Obtain the time points from the survival function
time_points = survival_probs[0].x

# Plot survival curves for a few examples
plot_survival_curves(survival_probs[:5], title="Random Survival Forest - Survival Curves")

# Compare actual vs. predicted survival probabilities
plt.figure(figsize=(10, 6))
plt.plot(time_points, np.mean(survival_probs, axis=0), label="Predicted Survival Probability", color="blue")
plt.step(time_points, 1 - np.cumsum(y_test["Overall Survival Status"]) / len(y_test), where="post", label="Actual Survival Probability", color="red")
plt.title("Comparison of Actual vs. Predicted Survival Probability")
plt.xlabel("Time (Months)")
plt.ylabel("Survival Probability")
plt.legend()
plt.show()

# Plot survival curves for actual and predicted outputs
plt.figure(figsize=(10, 6))

# Plot actual survival curve
plt.step(time_points, 1 - np.cumsum(y_test["Overall Survival (Months)"]) / len(y_test), where="post", label="Actual Survival Probability", color="red")

# Plot predicted survival curve (average over examples)
predicted_survival = np.mean(survival_probs, axis=0)
plt.step(time_points, predicted_survival, where="post", label="Predicted Survival Probability", color="blue")

plt.title("Comparison of Actual vs. Predicted Survival Probability")
plt.xlabel("Time (Months)")
plt.ylabel("Survival Probability")
plt.legend()
plt.show()

"""#**Just neural network**"""

import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Features (X) and target variable (y)
X = df.drop(['Overall Survival Status'], axis=1)
y = df['Overall Survival Status']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocess the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build the Coherent Voting Network
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))

# Predict probabilities for the positive class
y_probs = model.predict(X_test_scaled)

# Calculate AUROC
auroc = roc_auc_score(y_test, y_probs)
print(f"AUROC: {auroc}")

# Evaluate the model
y_pred = (y_probs > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}")

import shap
import numpy as np
# Use DeepExplainer for neural network models
explainer = shap.DeepExplainer(model, X_train_scaled)

# Generate Shap values for a subset of the data
shap_values = explainer.shap_values(X_test_scaled[:100])
# Visualize Shap values for a specific instance (e.g., the first instance)
shap.summary_plot(shap_values, X_test_scaled[:100], feature_names=X.columns)

shap.force_plot(explainer.expected_value[0], shap_values[0][0], X_test_scaled.iloc[0, :].to_frame().T, feature_names=X.columns)

"""#**After deleting the features**"""

import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Features (X) and target variable (y)
X = df.drop(['Overall Survival Status'], axis=1)
y = df['Overall Survival Status']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocess the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build the Coherent Voting Network
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))

# Predict probabilities for the positive class
y_probs = model.predict(X_test_scaled)

# Calculate AUROC
auroc = roc_auc_score(y_test, y_probs)
print(f"AUROC: {auroc}")

# Evaluate the model
y_pred = (y_probs > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}")

"""#**Coherent Voting Network**"""

import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Features (X) and target variable (y)
X = df.drop(['Overall Survival Status'], axis=1)
y = df['Overall Survival Status']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocess the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build the Just Neural Network (JNN)
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))

# Predict probabilities for the positive class
y_probs = model.predict(X_test_scaled)

# Calculate AUROC
auroc = roc_auc_score(y_test, y_probs)
print(f"AUROC: {auroc}")

# Evaluate the model
y_pred = (y_probs > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}")

import shap

# Assuming 'model' is your trained TensorFlow/Keras model and 'X_test_scaled' is your test data
explainer_shap = shap.Explainer(model, masker=shap.maskers.Independent(X_test_scaled))
shap_values = explainer_shap.shap_values(X_test_scaled)

# Summary Plot
shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns)

# Force Plot for a specific instance (you can change the index)
shap.force_plot(explainer_shap.expected_value, shap_values[0][0, :], X_test_scaled.iloc[0, :], feature_names=X.columns)

import lime
import lime.lime_tabular
import pandas as pd

# Convert X_test_scaled to a Pandas DataFrame
X_test_df = pd.DataFrame(X_test_scaled, columns=X.columns)

# Assuming 'X_train_scaled' is your training data
explainer_lime = lime.lime_tabular.LimeTabularExplainer(X_train_scaled, feature_names=X.columns, class_names=['Survived'], discretize_continuous=True)
lime_explanation = explainer_lime.explain_instance(X_test_df.iloc[0], model.predict, num_features=len(X.columns), top_labels=1)

# Explanation Summary
lime_explanation.show_in_notebook(show_table=True, show_all=False)

"""#**After features deletion**"""

import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Features (X) and target variable (y)
X = df.drop(['Overall Survival Status'], axis=1)
y = df['Overall Survival Status']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocess the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build the Just Neural Network (JNN)
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))

# Predict probabilities for the positive class
y_probs = model.predict(X_test_scaled)

# Calculate AUROC
auroc = roc_auc_score(y_test, y_probs)
print(f"AUROC: {auroc}")

# Evaluate the model
y_pred = (y_probs > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}")


# -*- coding: utf-8 -*-
"""Breast cancer_RFCC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TLkXWDB5hNmffqiUBFKdIkCSFaOtnymR
"""

!pip install pandas scikit-learn shap

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import shap

# Replace 'your_dataset_path.csv' with the actual path to your dataset
dataset_path = '/content/sample_data/Breast Cancer METABRIC.csv'
df = pd.read_csv(dataset_path)

df.isnull().sum()

for col in df.columns:
    df[col] = df[col].fillna(method='ffill')
    df[col] = df[col].fillna(method='bfill')

df

df.isnull().sum()

df = df.drop("Patient ID", axis=1)
df

X = df.drop("Patient's Vital Status", axis=1)
y = df["Patient's Vital Status"]
X = pd.get_dummies(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Make predictions on the training set
y_train_pred = rf_classifier.predict(X_train)

# Evaluate the model on the training set
train_accuracy = accuracy_score(y_train, y_train_pred)
print(f"Training Accuracy: {train_accuracy}")
print("\nTraining Classification Report:\n", classification_report(y_train, y_train_pred))

# Print the training confusion matrix
train_conf_matrix = confusion_matrix(y_train, y_train_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(train_conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=rf_classifier.classes_, yticklabels=rf_classifier.classes_)
plt.title("Training Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

y_test_pred = rf_classifier.predict(X_test)

# Evaluate the model on the test set
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f"\nTesting Accuracy: {test_accuracy}")
print("\nTesting Classification Report:\n", classification_report(y_test, y_test_pred))

# Print the testing confusion matrix
test_conf_matrix = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(test_conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=rf_classifier.classes_, yticklabels=rf_classifier.classes_)
plt.title("Testing Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# import shap

# # Create a SHAP explainer object
# explainer = shap.TreeExplainer(rf_classifier)

# # Calculate SHAP values for the test set
# shap_values = explainer.shap_values(X_test)

# # Summary plot
# shap.summary_plot(shap_values, X_test)

pip install lime

# from lime import lime_tabular
# import numpy as np

# # Create a LIME explainer object
# explainer = lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=rf_classifier.classes_, discretize_continuous=True)

# # Choose a random instance from the test set for explanation
# random_instance_idx = np.random.randint(0, len(X_test))
# instance_to_explain = X_test.iloc[random_instance_idx]

# # Generate LIME explanation for the chosen instance
# lime_explanation = explainer.explain_instance(instance_to_explain.values, rf_classifier.predict_proba)

# # Display the LIME explanation
# print("LIME Explanation for a Random Instance:")
# lime_explanation.show_in_notebook()

columns = ['Sex', 'Tumor Other Histologic Subtype', 'Neoplasm Histologic Grade', 'Cellularity', 'Lymph nodes examined positive', 'HER2 Status', 'Cohort', 'Radio Therapy', 'Inferred Menopausal State',
'PR Status', 'Cancer Type', 'ER status measured by IHC']
for col in columns:
    df = df.drop(col, axis=1)
df

df.info()



X = df.drop("Patient's Vital Status", axis=1)
y = df["Patient's Vital Status"]
X = pd.get_dummies(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

X_train

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Make predictions on the training set
y_train_pred = rf_classifier.predict(X_train)

# Evaluate the model on the training set
train_accuracy = accuracy_score(y_train, y_train_pred)
print(f"Training Accuracy: {train_accuracy}")
print("\nTraining Classification Report:\n", classification_report(y_train, y_train_pred))

# Print the training confusion matrix
train_conf_matrix = confusion_matrix(y_train, y_train_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(train_conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=rf_classifier.classes_, yticklabels=rf_classifier.classes_)
plt.title("Training Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

y_test_pred = rf_classifier.predict(X_test)

# Evaluate the model on the test set
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f"\nTesting Accuracy: {test_accuracy}")
print("\nTesting Classification Report:\n", classification_report(y_test, y_test_pred))

# Print the testing confusion matrix
test_conf_matrix = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(test_conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=rf_classifier.classes_, yticklabels=rf_classifier.classes_)
plt.title("Testing Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# Creating an example individual data point with an index
individual_data = pd.DataFrame({
    'Age at Diagnosis': [75.65],  # Note the use of a list for scalar values
    'Type of Breast Surgery': ['Mastectomy'],
    'Cancer Type Detailed': ['Breast Invasive Ductal Carcinoma'],
    'Chemotherapy': ['No'],
    'Pam50 + Claudin-low subtype': ['claudin-low'],
    'ER Status': ['Positive'],
    'HER2 status measured by SNP6': ['Negative'],
    'Hormone Therapy': ['Yes'],
    'Integrative Cluster': [1],
    'Primary Tumor Laterality': ['Right'],
    'Mutation Count': [10],
    'Nottingham prognostic index': [6.044],
    'Oncotree Code': ['IDC'],
    'Overall Survival (Months)': [140.5],
    'Overall Survival Status': ['Living'],
    'Relapse Free Status (Months)': [138.65],
    'Relapse Free Status': ['Not Recurred'],
    '3-Gene classifier subtype': ['ER-/HER2-'],
    'Tumor Size': [22],
    'Tumor Stage': [2],
}, index=['MB-0000'])  # Specify the index

# Preprocess the individual data point
individual_data_preprocessed = pd.get_dummies(individual_data)

# # Ensure that the column order and names match the training data
# individual_data_preprocessed = individual_data_preprocessed[X_train.columns]

# Match columns and handle missing columns
for column in X_train.columns:
    if column not in individual_data_preprocessed.columns:
        individual_data_preprocessed[column] = 0

# Ensure the columns are in the same order
individual_data_preprocessed = individual_data_preprocessed[X_train.columns]

# Predict the outcome for the individual data point
individual_prediction = rf_classifier.predict(individual_data_preprocessed)

# Print or use the prediction
print("Predicted Outcome:", individual_prediction)

# Creating an example individual data point for MB-0008
individual_data_mb_0008 = pd.DataFrame({
    'Age at Diagnosis': [76.97],
    'Type of Breast Surgery': ['Mastectomy'],
    'Cancer Type Detailed': ['Breast Mixed Ductal and Lobular Carcinoma'],
    'Chemotherapy': ['Yes'],
    'Pam50 + Claudin-low subtype': ['LumB'],
    'ER Status': ['Positive'],
    'HER2 status measured by SNP6': ['Negative'],
    'Hormone Therapy': ['Yes'],
    'Integrative Cluster': [1],
    'Primary Tumor Laterality': ['Right'],
    'Mutation Count': [8],
    'Nottingham prognostic index': [6.08],
    'Oncotree Code': ['MDLC'],
    'Overall Survival (Months)': [41.36666667],
    'Overall Survival Status': ['Deceased'],
    'Relapse Free Status (Months)': [14.33],
    'Relapse Free Status': ['Recurred'],
    '3-Gene classifier subtype': ['ER+/HER2- High Prolif'],
    'Tumor Size': [40],
    'Tumor Stage': [2],
}, index=['MB-0008'])

# Match columns and handle missing columns
for column in X_train.columns:
    if column not in individual_data_mb_0008.columns:
        individual_data_mb_0008[column] = 0

# Ensure the columns are in the same order
individual_data_mb_0008 = individual_data_mb_0008[X_train.columns]

# Preprocess the individual data point
individual_data_mb_0008_preprocessed = pd.get_dummies(individual_data_mb_0008)

# Ensure that the columns of individual_data_preprocessed match the columns used during training
missing_columns = set(X_train.columns) - set(individual_data_mb_0008_preprocessed.columns)
for column in missing_columns:
    individual_data_mb_0008_preprocessed[column] = 0

# Predict the outcome for the individual data point
individual_prediction_mb_0008 = rf_classifier.predict(individual_data_mb_0008_preprocessed)

# Print or use the prediction
print("Predicted Outcome for MB-0008:", individual_prediction_mb_0008)

# Creating an example individual data point for MB-0008 without an explicit index
individual_data = pd.DataFrame({
    'Age at Diagnosis': [76.97],
    'Type of Breast Surgery': ['Mastectomy'],
    'Cancer Type Detailed': ['Breast Mixed Ductal and Lobular Carcinoma'],
    'Chemotherapy': ['Yes'],
    'Pam50 + Claudin-low subtype': ['LumB'],
    'ER Status': ['Positive'],
    'HER2 status measured by SNP6': ['Negative'],
    'Hormone Therapy': ['Yes'],
    'Integrative Cluster': [1],
    'Primary Tumor Laterality': ['Right'],
    'Mutation Count': [8],
    'Nottingham prognostic index': [6.08],
    'Oncotree Code': ['MDLC'],
    'Overall Survival (Months)': [41.36666667],
    'Overall Survival Status': ['Deceased'],
    'Relapse Free Status (Months)': [18.55],
    'Relapse Free Status': ['Recurred'],
    '3-Gene classifier subtype': ['ER+/HER2- High Prolif'],
    'Tumor Size': [40],
    'Tumor Stage': [2],
})

# Match columns and handle missing columns
for column in X_train.columns:
    if column not in individual_data.columns:
        individual_data[column] = 0

# Ensure the columns are in the same order
individual_data = individual_data[X_train.columns]

# Preprocess the individual data point
individual_data_preprocessed = pd.get_dummies(individual_data)

# Ensure that the columns of individual_data_preprocessed match the columns used during training
missing_columns = set(X_train.columns) - set(individual_data_preprocessed.columns)
for column in missing_columns:
    individual_data_preprocessed[column] = 0

# Predict the outcome for the individual data point
individual_prediction = rf_classifier.predict(individual_data_preprocessed)

# Print or use the prediction
print("Predicted Outcome:", individual_prediction)

import numpy as np

# Create an example individual data point with random values
individual_data_random = pd.DataFrame({
    'Age at Diagnosis': [45],
    'Type of Breast Surgery': ['Mastectomy'],
    'Cancer Type Detailed': ['Breast Invasive Ductal Carcinoma'],
    'Chemotherapy': ['Yes'],
    'Pam50 + Claudin-low subtype': ['LumA'],
    'ER Status': ['Negative'],
    'HER2 status measured by SNP6': ['Negative'],
    'Hormone Therapy': ['Yes'],
    'Integrative Cluster':  [2],
    'Primary Tumor Laterality': ['Right'],
    'Mutation Count': [4],
    'Nottingham prognostic index': [6],
    'Oncotree Code': ['MDLC'],
    'Overall Survival (Months)': [30],
    'Overall Survival Status': ['Living'],
    'Relapse Free Status (Months)': [112.4],
    'Relapse Free Status': ['Not Recurred'],
    '3-Gene classifier subtype': ['ER+/HER2-'],
    'Tumor Size': [24],
    'Tumor Stage':  [2],
}, index=[0])

# Match columns and handle missing columns
for column in X_train.columns:
    if column not in individual_data_random.columns:
        individual_data_random[column] = 0

# Ensure the columns are in the same order
individual_data_random = individual_data_random[X_train.columns]

# Preprocess the individual data point
individual_data_random_preprocessed = pd.get_dummies(individual_data_random)

# Ensure that the columns of individual_data_random_preprocessed match the columns used during training
missing_columns = set(X_train.columns) - set(individual_data_random_preprocessed.columns)
for column in missing_columns:
    individual_data_random_preprocessed[column] = 0

# Predict the outcome for the random individual data point
individual_prediction_random = rf_classifier.predict(individual_data_random_preprocessed)

# Print or use the prediction
print("Predicted Outcome for Random Individual Data:", individual_prediction_random)

from sklearn.preprocessing import label_binarize

# Binarize the labels for multiclass ROC and precision-recall curves
y_train_bin = label_binarize(y_train, classes=rf_classifier.classes_)
y_test_bin = label_binarize(y_test, classes=rf_classifier.classes_)

# Get predicted probabilities for the positive class
y_train_prob = rf_classifier.predict_proba(X_train)
y_test_prob = rf_classifier.predict_proba(X_test)

# Plot ROC curve for training set (one-vs-rest)
fpr_train = dict()
tpr_train = dict()
roc_auc_train = dict()

for i in range(len(rf_classifier.classes_)):
    fpr_train[i], tpr_train[i], _ = roc_curve(y_train_bin[:, i], y_train_prob[:, i])
    roc_auc_train[i] = auc(fpr_train[i], tpr_train[i])

plt.figure(figsize=(8, 6))
for i in range(len(rf_classifier.classes_)):
    plt.plot(fpr_train[i], tpr_train[i], lw=2, label=f'Class {i} (AUC = {roc_auc_train[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Training Set (One-vs-Rest)')
plt.legend(loc='lower right')
plt.show()

# Plot ROC curve for testing set (one-vs-rest)
fpr_test = dict()
tpr_test = dict()
roc_auc_test = dict()

for i in range(len(rf_classifier.classes_)):
    fpr_test[i], tpr_test[i], _ = roc_curve(y_test_bin[:, i], y_test_prob[:, i])
    roc_auc_test[i] = auc(fpr_test[i], tpr_test[i])

plt.figure(figsize=(8, 6))
for i in range(len(rf_classifier.classes_)):
    plt.plot(fpr_test[i], tpr_test[i], lw=2, label=f'Class {i} (AUC = {roc_auc_test[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Testing Set (One-vs-Rest)')
plt.legend(loc='lower right')
plt.show()

# Plot Precision-Recall curve for training set (one-vs-rest)
precision_train = dict()
recall_train = dict()
average_precision_train = dict()

for i in range(len(rf_classifier.classes_)):
    precision_train[i], recall_train[i], _ = precision_recall_curve(y_train_bin[:, i], y_train_prob[:, i])
    average_precision_train[i] = average_precision_score(y_train_bin[:, i], y_train_prob[:, i])

plt.figure(figsize=(8, 6))
for i in range(len(rf_classifier.classes_)):
    plt.step(recall_train[i], precision_train[i], where='post', label=f'Class {i} (AP = {average_precision_train[i]:.2f})')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall curve - Training Set (One-vs-Rest)')
plt.legend(loc='upper right')
plt.show()

# Plot Precision-Recall curve for testing set (one-vs-rest)
precision_test = dict()
recall_test = dict()
average_precision_test = dict()

for i in range(len(rf_classifier.classes_)):
    precision_test[i], recall_test[i], _ = precision_recall_curve(y_test_bin[:, i], y_test_prob[:, i])
    average_precision_test[i] = average_precision_score(y_test_bin[:, i], y_test_prob[:, i])

plt.figure(figsize=(8, 6))
for i in range(len(rf_classifier.classes_)):
    plt.step(recall_test[i], precision_test[i], where='post', label=f'Class {i} (AP = {average_precision_test[i]:.2f})')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall curve - Testing Set (One-vs-Rest)')
plt.legend(loc='upper right')
plt.show()

import numpy as np

# Sort the indices for plotting
sorted_indices = np.argsort(y_test.values)

# Plot the actual vs. predicted outputs using a line graph
plt.figure(figsize=(10, 6))
plt.plot(np.arange(len(y_test)), y_test.iloc[sorted_indices].values, label='Actual', marker='o', color='blue')
plt.plot(np.arange(len(y_test_pred)), y_test_pred[sorted_indices], label='Predicted', marker='o', color='black')

plt.xlabel('Sorted Example Index')
plt.ylabel('Class')
plt.title('Actual vs. Predicted Outputs (Test Set)')
plt.legend()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Plot histogram for actual labels
plt.figure(figsize=(10, 6))
sns.histplot(y_test, kde=True, color='blue', label='Actual', stat='probability')

# Plot histogram for predicted labels
sns.histplot(y_test_pred, kde=True, color='red', label='Predicted', stat='probability')

plt.xlabel('Class')
plt.ylabel('Probability')
plt.title('Distribution of Actual and Predicted Outputs (Test Set)')
plt.legend()
plt.show()

